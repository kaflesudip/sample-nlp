{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets define some configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_IS_PYTHON_3 = sys.version_info.major == 3\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# The low end of shared words to consider\n",
    "LOWER_BOUND = .20\n",
    "\n",
    "# The high end, since anything above this is probably SEO garbage or a\n",
    "# duplicate sentence\n",
    "UPPER_BOUND = .90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Support for both Python 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def u(s):\n",
    "    \"\"\"Ensure our string is unicode independent of Python version, since Python 3 versions < 3.3 do not support the u\"...\" prefix\"\"\"\n",
    "    if _IS_PYTHON_3 or type(s) == unicode:\n",
    "        return s\n",
    "    else:\n",
    "        # not well documented but seems to work\n",
    "        return codecs.unicode_escape_decode(s)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual function for Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_unimportant(word):\n",
    "    \"\"\"Decides if a word is ok to toss out for the sentence comparisons\"\"\"\n",
    "    return word in ['.', '!', ',', ] or '\\'' in word or word in stop_words\n",
    "\n",
    "\n",
    "def only_important(sent):\n",
    "    \"\"\"Just a little wrapper to filter on is_unimportant\"\"\"\n",
    "    return filter(lambda w: not is_unimportant(w), sent)\n",
    "\n",
    "\n",
    "def compare_sents(sent1, sent2):\n",
    "    \"\"\"Compare two word-tokenized sentences for shared words\"\"\"\n",
    "    if not len(sent1) or not len(sent2):\n",
    "        return 0\n",
    "    return len(set(only_important(sent1)) & set(only_important(sent2))) / ((len(sent1) + len(sent2)) / 2.0)\n",
    "\n",
    "\n",
    "def compare_sents_bounded(sent1, sent2):\n",
    "    \"\"\"If the result of compare_sents is not between LOWER_BOUND and\n",
    "    UPPER_BOUND, it returns 0 instead, so outliers don't mess with the sum\"\"\"\n",
    "    cmpd = compare_sents(sent1, sent2)\n",
    "    if cmpd <= LOWER_BOUND or cmpd >= UPPER_BOUND:\n",
    "        return 0\n",
    "    return cmpd\n",
    "\n",
    "\n",
    "def compute_score(sent, sents):\n",
    "    \"\"\"Computes the average score of sent vs the other sentences (the result of\n",
    "    sent vs itself isn't counted because it's 1, and that's above\n",
    "    UPPER_BOUND)\"\"\"\n",
    "    if not len(sent):\n",
    "        return 0\n",
    "    return sum(compare_sents_bounded(sent, sent1) for sent1 in sents) / float(len(sents))\n",
    "\n",
    "\n",
    "def summarize_block(block):\n",
    "    \"\"\"Return the sentence that best summarizes block\"\"\"\n",
    "    if not block:\n",
    "        return None\n",
    "    sents = nltk.sent_tokenize(block)\n",
    "    word_sents = list(map(nltk.word_tokenize, sents))\n",
    "    d = dict((compute_score(word_sent, word_sents), sent)\n",
    "             for sent, word_sent in zip(sents, word_sents))\n",
    "    return d[max(d.keys())]\n",
    "\n",
    "\n",
    "def find_likely_body(b):\n",
    "    \"\"\"Find the tag with the most directly-descended <p> tags\"\"\"\n",
    "    return max(b.find_all(), key=lambda t: len(t.find_all('p', recursive=False)))\n",
    "\n",
    "\n",
    "class Summary(object):\n",
    "\n",
    "    def __init__(self, url, article_html, title, summaries):\n",
    "        self.url = url\n",
    "        self.article_html = article_html\n",
    "        self.title = title\n",
    "        self.summaries = summaries\n",
    "\n",
    "    def __repr__(self):\n",
    "        return u('Summary({}, {}, {}, {})').format(repr(self.url), repr(self.article_html), repr(self.title), repr(self.summaries))\n",
    "\n",
    "    def __unicode__(self):\n",
    "        return u('{} - {}\\n\\n{}').format(self.title, self.url, '\\n'.join(self.summaries))\n",
    "\n",
    "    def __str__(self):\n",
    "        if _IS_PYTHON_3:\n",
    "            return self.__unicode__()\n",
    "        else:\n",
    "            return self.__unicode__().encode('utf8')\n",
    "\n",
    "\n",
    "def summarize_blocks(blocks):\n",
    "    summaries = [re.sub('\\s+', ' ', summarize_block(block) or '').strip()\n",
    "                 for block in blocks]\n",
    "    # deduplicate and preserve order\n",
    "    summaries = sorted(set(summaries), key=summaries.index)\n",
    "    return [u(re.sub('\\s+', ' ', summary.strip())) for summary in summaries if any(c.lower() in string.ascii_lowercase for c in summary)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Beautiful Soup to parse URL and return the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_page(url):\n",
    "    import bs4\n",
    "    import requests\n",
    "\n",
    "    html = bs4.BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "    b = find_likely_body(html)\n",
    "    summaries = summarize_blocks(map(lambda p: p.text, b.find_all('p')))\n",
    "    return Summary(url, b, html.title.text if html.title else None, summaries)\n",
    "\n",
    "\n",
    "def summarize_text(text, block_sep='\\n\\n', url=None, title=None):\n",
    "    return Summary(url, None, title, summarize_blocks(text.split(block_sep)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets test with some urls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBI pledges to assist local police in unlocking iPhones - CBS News - http://www.cbsnews.com/news/fbi-pledges-to-assist-local-police-in-unlocking-iphones/\n",
      "\n",
      "Less than a week after the FBI was able to unlock an iPhone used by the San Bernardino shooter Syed Farook, the federal investigators are pledging to help local law enforcement departments facing similar problems.\n",
      "In a letter to local police departments, the FBI offered their assistance in hacking the Apple phones in cases where they could provide evidence.\n",
      "In CBSN's business headlines Jill Wagner gives details on the FBI iPhone hack, Boeing job cuts, and how housing costs have risen at a faster pace...\n",
      "\"We know that the absence of lawful, critical investigative tools due to the 'Going Dark' problem is a substantial state and local law enforcement challenge that you face daily,\" reads the FBI letter, obtained by CBS News.\n",
      "Earlier this week, the Department of Justice dropped its attempts to legally compel Apple to assist in unlocking the now-infamous San Bernardino iPhone, avoiding a looming showdown between the technology giant and the federal government.\n",
      "The Justice Department declined to name the outside party involved and has not given details about the decryption technique.\n",
      "A government official confirmed to CBS News earlier this week that the FBI now owns the proprietary rights to that method.\n",
      "The FBI's help is already in demand from local law enforcement.\n",
      "CBS News' Jeff Pegues and Kathleen Johnston contributed to this report.\n"
     ]
    }
   ],
   "source": [
    "print(summarize_page(\"http://www.cbsnews.com/news/fbi-pledges-to-assist-local-police-in-unlocking-iphones/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
